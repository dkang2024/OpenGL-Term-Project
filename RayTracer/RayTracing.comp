// Initialize the version
#version 460 core

layout(binding = 1) uniform sampler2D brickWall;
layout(binding = 2) uniform sampler2D earth;

// Import files here using the "include" statement that Python processes with string processing and txt file processing
#include "Random"
#include "Vectors"
#include "Ray"
#include "Interval"
#include "HitRecord"
#include "Materials"
#include "Camera"
#include "Textures"
#include "Sphere"
#include "Quad"

// Set up invocation size and take in the screen texture to modify it per pixel. Note that the size volume is 32 (which is optimized for NVIDIA gpus rather than AMD gpus [which prefer a size of multiples of 64])
layout(local_size_x = 8, local_size_y = 4, local_size_z = 1) in;
layout(rgba32f, binding = 0) uniform image2D screen;
layout(rgba32ui, binding = 1) uniform uimage2D seeds;

layout(std430, binding = 0) buffer scene1 {
    sphere3 spheres[];
};
layout(std430, binding = 1) buffer scene2 {
    quad3 quads[];
};

uniform int numSpheres;
uniform int numQuads;
uniform int maxBounces;
uniform int rootSPP;
uniform float invRootSPP;
uniform viewerCamera camera;

// Create a gradient from the top of the screen to the bottom of the screen based on the ray's y direction 
vec3 gradientColor(vec3 rayDirection){
    float rayDirY = normalize(rayDirection).y;
    float t = 0.5 * (rayDirY + 1.0);

    vec3 colorTop = vec3(1.0, 1.0, 1.0);
    vec3 colorBottom = vec3(0.5, 0.7, 1.0);

    return mix(colorTop, colorBottom, t);
}

// Sample within the pixel's square from -0.5 to 0.5 in order to do some antialiasing (also stratify to increase dimensionality but converge faster for randomness)
vec2 samplePixel(int i, int j, inout uvec4 state){
    float pixelX = ((i + rand(state)) * invRootSPP) - 0.5;
    float pixelY = ((j + rand(state)) * invRootSPP) - 0.5;
    return vec2(pixelX, pixelY);
}

// Construct a ray from a camera to the viewport depending on the pixel coordinate (use stratified sampling also)
ray3 constructCameraRay(ivec2 pixelCoord, int i, int j, inout uvec4 state){
    vec2 sampledVector = samplePixel(i, j, state);
    vec3 rayDir = camera.initPixelPos + (pixelCoord.x + sampledVector.x) * camera.pixelDX + (pixelCoord.y + sampledVector.y) * camera.pixelDY - camera.position;
    struct ray3 ray = {camera.position, normalize(rayDir)};
    return ray;
}

// Check if a ray hits any hittable and update a hit record to show the ray's color and reflect that change. 
bool hit(ray3 ray, inout hitRecord record, inout uvec4 state){
    bool didHit = false; 
    for (int i = 0; i < numSpheres; i++){
        if (hitSphere(spheres[i], ray, record, state)){
            didHit = true; 
        }
    }
    for (int i = 0; i < numQuads; i++){
        if (hitQuad(quads[i], ray, record, state)){
            didHit = true;
        }
    }
    return didHit;
}

// Apply the rendering equation with Monte Carlo integration to determine the object color
vec3 renderingEQ(inout hitRecord record, inout uvec4 state){
    if (record.materialID == 0){
        vec3 onLight = vec3(randRange(state, 213, 343), 554, randRange(state, 227, 332));
        vec3 toLight = onLight - record.pointHit;
        float distanceSquared = dot(toLight, toLight);
        toLight = normalize(toLight);

        float cosToLight = dot(toLight, record.normalVector);
        if (dot(toLight, record.normalVector) < 0){
            return vec3(0);        
        }

        float lightArea = (343 - 213) * (332 - 227);
        float lightCosine = abs(toLight.y);

        if (lightCosine < 1e-6){
            return vec3(0);
        }
       
        float lightPDF = distanceSquared / (lightCosine * lightArea);
        return lambertianBRDF(record.objectColor) * cosToLight / lightPDF;
    } 
    return record.objectColor;
}

// Get the pixel color while still reflecting the ray (bouncing it off of surfaces)
vec3 pixelColor(inout ray3 ray, inout uvec4 state){
    vec3 accumulatedColor = vec3(0);
    vec3 throughput = vec3(1);
    
    for (int i = 0; i < maxBounces; i++){
        hitRecord record = initDefaultHitRecord();

        if (!hit(ray, record, state)){
            accumulatedColor += throughput * vec3(0);
            break;
        } 
        
        // Apply the rendering equation here. Don't allow any more bounces for light so don't ADD emissive. Just multiply by the color

        if (record.isLight){
            accumulatedColor += throughput * record.objectColor;
            break;
        }

        vec3 on_light = vec3((213 + 343) / 2, 554, (227 + 332) / 2);
        vec3 to_light = on_light - record.pointHit;

        float distance_squared = dot(to_light, to_light);
        to_light = normalize(to_light);

        float light_area = (343-213)*(332-227);
        float light_cosine = abs(to_light.y);

        if (abs(record.pointHit.x - 555) < 5){
            return vec3(1, 0, 0);
        } else {
            return vec3(1);
        }
        
        float pdf_value = distance_squared / (light_area);
        
        return lambertianBRDF(record.objectColor) / pdf_value;
    
        if (record.didScatter){
            ray = record.scatteredRay;
        } else {
            accumulatedColor += throughput;
            break;
        }
    }
    return accumulatedColor;
}

// Gamut correction
vec3 gamutCorrect(vec3 pixel){
    return sqrt(pixel);
}

// Implement basic antialiasing (with stratified random sampling to make the Monte Carlo path tracing converge faster at the cost of increasing dimensions) using a random point in the pixel to shoot rays through and averaging color
vec4 antialiasing(ivec2 pixelCoord, inout uvec4 state){
    vec3 pixel = initDefaultVec();
    for (int i = 0; i < rootSPP; i++){
        for (int j = 0; j < rootSPP; j++){
            ray3 cameraRay = constructCameraRay(pixelCoord, i, j, state);
            pixel += pixelColor(cameraRay, state);
        }
    }
    return vec4(gamutCorrect(pixel / pow(rootSPP, 2)), 1);
}

// Main Function
void main(){
    ivec2 pixelCoord = ivec2(gl_GlobalInvocationID.xy); // Get the global invocation ID in order to determine the exact pixel location. 
    uvec4 state = imageLoad(seeds, pixelCoord);
    vec4 pixel = antialiasing(pixelCoord, state);

    imageStore(seeds, pixelCoord, state);
    imageStore(screen, pixelCoord, pixel);
}