// Initialize the version
#version 460 core

// Import files here using the "include" statement that Python processes with string processing and txt file processing
#include "Random"
#include "Vectors"
#include "Ray"
#include "Interval"
#include "HitRecord"
#include "Materials"
#include "Camera"
#include "Sphere"

// Set up invocation size and take in the screen texture to modify it per pixel. Note that the size volume is 32 (which is optimized for NVIDIA gpus rather than AMD gpus [which prefer a size of multiples of 64])
layout(local_size_x = 8, local_size_y = 4, local_size_z = 1) in;
layout(rgba32f, binding = 0) uniform image2D screen;
layout(rgba32ui, binding = 1) uniform uimage2D seeds;

layout(std430, binding = 0) buffer worldScene {
    sphere3 hittables[];
};

uniform int numHittables;
uniform int maxBounces;
uniform int samplesPerPixel;
uniform viewerCamera camera;

// Create a gradient from the top of the screen to the bottom of the screen based on the ray's y direction 
vec3 gradientColor(vec3 rayDirection){
    float rayDirY = normalize(rayDirection).y;
    float t = 0.5 * (rayDirY + 1.0);

    vec3 colorTop = vec3(1.0, 1.0, 1.0);
    vec3 colorBottom = vec3(0.5, 0.7, 1.0);

    return mix(colorTop, colorBottom, t);
}

// Sample within the pixel's square from -0.5 to 0.5 in order to do some antialiasing
vec2 samplePixel(inout uvec4 state){
    vec2 sampledVector = vec2(randRange(state, -0.5, 0.5), randRange(state, -0.5, 0.5));
    return sampledVector;
}

// Construct a ray from a camera to the viewport depending on the pixel coordinate
ray3 constructCameraRay(ivec2 pixelCoord, inout uvec4 state){
    vec2 sampledVector = samplePixel(state);
    vec3 rayDir = camera.initPixelPos + (pixelCoord.x + sampledVector.x) * camera.pixelDX + (pixelCoord.y + sampledVector.y) * camera.pixelDY - camera.position;
    struct ray3 ray = {camera.position, rayDir};
    return ray;
}

// Check if a ray hits any hittable and update a hit record to show the ray's color and reflect that change. 
bool hit(inout hitRecord record, inout uvec4 state){
    bool didHit = false; 
    for (int i = 0; i < numHittables; i++){
        if (hitSphere(hittables[i], record, state)){
            didHit = true; 
        }
    }
    return didHit;
}

// Get the pixel color while still reflecting the ray (bouncing it off of surfaces)
vec3 pixelColor(ivec2 pixelCoord, inout uvec4 state){
    ray3 cameraRay = constructCameraRay(pixelCoord, state);
    hitRecord record = initDefaultHitRecord(cameraRay);

    for (int i = 0; i < maxBounces; i++){
        bool didHit = hit(record, state);

        if (didHit && !record.didScatter){
            break;
        } else if (!didHit){
            return record.rayColor * gradientColor(record.ray.direction);
        }
    }
    return vec3(0.0, 0.0, 0.0);
}

// Implement basic antialiasing using a random point in the pixel to shoot rays through and averaging color
vec4 antialiasing(ivec2 pixelCoord, inout uvec4 state){
    vec3 pixel = initDefaultVec();
    for (int i = 0; i < samplesPerPixel; i++){
        pixel += pixelColor(pixelCoord, state);
    }
    return vec4(pixel / samplesPerPixel, 1.0);
}

// Main Function
void main(){
    ivec2 pixelCoord = ivec2(gl_GlobalInvocationID.xy); // Get the global invocation ID in order to determine the exact pixel location. 
    uvec4 state = imageLoad(seeds, pixelCoord);
    vec4 pixel = antialiasing(pixelCoord, state);

    imageStore(seeds, pixelCoord, state);
    imageStore(screen, pixelCoord, pixel);
}