// Initialize the version
#version 460 core

layout(binding = 1) uniform sampler2D brickWall;
layout(binding = 2) uniform sampler2D earth;

// Import files here using the "include" statement that Python processes with string processing and txt file processing
#include "Random"
#include "Vectors"
#include "Ray"
#include "Interval"
#include "HitRecord"
#include "Materials"
#include "Camera"
#include "Textures"
#include "Sphere"
#include "Quad"

// Set up invocation size and take in the screen texture to modify it per pixel. Note that the size volume is 32 (which is optimized for NVIDIA gpus rather than AMD gpus [which prefer a size of multiples of 64])
layout(local_size_x = 8, local_size_y = 4, local_size_z = 1) in;
layout(rgba32f, binding = 0) uniform image2D screen;
layout(rgba32ui, binding = 1) uniform uimage2D seeds;

layout(std430, binding = 0) buffer scene1 {
    Sphere spheres[];
};
layout(std430, binding = 1) buffer scene2 {
    Quad quads[];
};
layout(std430, binding = 2) buffer scene3 {
    Quad lights[];
};

uniform int numSpheres;
uniform int numQuads;
uniform int numLights;
uniform int maxBounces;
uniform int rootSPP;
uniform float invRootSPP;
uniform viewerCamera camera;

// Create a gradient from the top of the screen to the bottom of the screen based on the ray's y direction 
vec3 gradientColor(vec3 rayDirection){
    float rayDirY = normalize(rayDirection).y;
    float t = 0.5 * (rayDirY + 1.0);

    vec3 colorTop = vec3(1.0, 1.0, 1.0);
    vec3 colorBottom = vec3(0.5, 0.7, 1.0);

    return mix(colorTop, colorBottom, t);
}

// Return the background color
vec3 backgroundColor(vec3 rayDir){
    return vec3(0);
}

// Sample within the pixel's square from -0.5 to 0.5 in order to do some antialiasing (also stratify to increase dimensionality but converge faster for randomness)
vec2 samplePixel(int i, int j, inout uvec4 state){
    float pixelX = ((i + rand(state)) * invRootSPP) - 0.5;
    float pixelY = ((j + rand(state)) * invRootSPP) - 0.5;
    return vec2(pixelX, pixelY);
}

// Construct a ray from a camera to the viewport depending on the pixel coordinate (use stratified sampling also)
Ray constructCameraRay(ivec2 pixelCoord, int i, int j, inout uvec4 state){
    vec2 sampledVector = samplePixel(i, j, state);
    vec3 rayDir = camera.initPixelPos + (pixelCoord.x + sampledVector.x) * camera.pixelDX + (pixelCoord.y + sampledVector.y) * camera.pixelDY - camera.position;
    return Ray(camera.position, rayDir);
}

// Check if a ray hits any hittable and update a hit record to show the ray's color and reflect that change. 
bool hit(Ray ray, inout HitRecord record, inout uvec4 state){
    bool didHit = false; 
    for (int i = 0; i < numSpheres; i++){
        if (hitSphere(spheres[i], ray, record, state)){
            didHit = true; 
        }
    }
    for (int i = 0; i < numQuads; i++){
        if (hitQuad(quads[i], ray, record, state)){
            didHit = true;
        }
    }
    for (int i = 0; i < numLights; i++){
        if (hitQuad(lights[i], ray, record, state)){
            didHit = true;
        }
    }
    return didHit;
}

// Check if a light is visible 
bool lightVisible(Ray ray, float lightTime, int lightIndex){
    Interval lightInterval = {rayMin, lightTime};
    for (int i = 0; i < numSpheres; i++){
        if (hitSphereLight(spheres[i], ray, lightInterval)){
            return false; 
        }
    }
    for (int i = 0; i < numQuads; i++){
        if (hitQuadLight(quads[i], ray, lightInterval)){
            return false; 
        }
    }
    for (int i = 0; i < numLights; i++){
        if (i == lightIndex){
            continue;
        } else if (hitQuadLight(lights[i], ray, lightInterval)){
            return false;
        }
    }
    return true;
}

// Lambertian rendering equation (with direct light sampling and shadow rays implemented)
void renderingEQ(inout HitRecord record, inout vec3 throughput, inout uvec4 state){
    Ray lightRay;
    float lightTime;

    vec3 directLight = vec3(0);

    for (int i = 0; i < numLights; i++){
        int lightIndex = randInt(state, 0, numLights);

        float lightPDF = quadLightPDF(lights[lightIndex], record, lightTime, lightRay, state);
        if (lightVisible(lightRay, lightTime, lightIndex)){
            directLight += lambertianBRDF(record.objectColor) * scatteredCos(record.normalVector, record.scatteredRay.direction) * lights[lightIndex].color / lightPDF;
        } 
    }
    throughput *= directLight;
}

// Get the pixel color while still reflecting the ray (bouncing it off of surfaces)
vec3 pixelColor(Ray ray, inout uvec4 state){
    vec3 accumulatedColor = vec3(0);
    vec3 throughput = vec3(1);
    int prevMaterialID;
    
    for (int bounce = 0; bounce < maxBounces; bounce++){
        HitRecord record = initDefaultHitRecord();

        if (!hit(ray, record, state)){
            accumulatedColor += throughput * backgroundColor(vec3(0));
            break;
        } 
        
        if (record.isLight){ 
            if (bounce == 0 || prevMaterialID != LAMBERTIAN){ // Check these conditions to avoid double dipping the light source with the direct light sampling. If the previous material was lambertian, then I already accounted for the direct light. 
                accumulatedColor += throughput * record.objectColor;
            } else {
                accumulatedColor += throughput;  
            }
            break; // Break at the light (separate from regular renderers because it allows me to simplify calculations)
        } 

        prevMaterialID = record.materialID;
        if (record.materialID == LAMBERTIAN){
            renderingEQ(record, throughput, state);
            accumulatedColor += throughput;
            break;
        } else {
            throughput *= record.objectColor;
        }
    
        if (record.didScatter){
            ray = record.scatteredRay;
        } else {
            accumulatedColor += throughput;
            break;
        }
    }
    return accumulatedColor;
}

// Gamut correction
vec3 gamutCorrect(vec3 pixel){
    return sqrt(pixel);
}

// Implement basic antialiasing (with stratified random sampling to make the Monte Carlo path tracing converge faster at the cost of increasing dimensions) using a random point in the pixel to shoot rays through and averaging color
vec4 antialiasing(ivec2 pixelCoord, inout uvec4 state){
    vec3 pixel = initDefaultVec();
    for (int i = 0; i < rootSPP; i++){
        for (int j = 0; j < rootSPP; j++){
            Ray cameraRay = constructCameraRay(pixelCoord, i, j, state);
            pixel += pixelColor(cameraRay, state);
        }
    }
    return vec4(gamutCorrect(pixel / pow(rootSPP, 2)), 1);
}

// Main Function
void main(){
    ivec2 pixelCoord = ivec2(gl_GlobalInvocationID.xy); // Get the global invocation ID in order to determine the exact pixel location. 
    uvec4 state = imageLoad(seeds, pixelCoord);
    vec4 pixel = antialiasing(pixelCoord, state);

    imageStore(seeds, pixelCoord, state);
    imageStore(screen, pixelCoord, pixel);
}