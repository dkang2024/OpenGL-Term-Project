// Initialize the version
#version 460 core

layout(binding = 0) uniform sampler2D screen1Texture;
layout(binding = 1) uniform sampler2D screen2Texture;
layout(binding = 2) uniform samplerCube grassTexture;

// Set up invocation size and take in the screen texture to modify it per pixel. Note that the size volume is 32 (which is optimized for NVIDIA gpus rather than AMD gpus [which prefer a size of multiples of 64])
layout(local_size_x = 8, local_size_y = 4, local_size_z = 1) in;

layout(rgba32f, binding = 0) uniform image2D screen1;
layout(rgba32f, binding = 1) uniform image2D screen2;
layout(rgba32f, binding = 2) uniform image3D world;
layout(rgba32ui, binding = 3) uniform uimage2D seeds;

uniform int frameCount;
uniform float temporalReuseFactor;
uniform int maxRaySteps;
uniform mat4 prevViewProj;

// Import files here using the "include" statement that Python processes with string processing and txt file processing
#include "Random"
#include "Vectors"
#include "Ray"
#include "Interval"
#include "HitRecord"
#include "Materials"
#include "Camera"
#include "Textures"
#include "TAA" 
#include "Light"
#include "Reservoir"
#include "Quad"

uniform int numLights;
uniform int maxBounces;
uniform int rootSPP;
uniform float invRootSPP;
uniform int badLightSamples;
uniform ViewerCamera camera;

layout(std430, binding = 0) buffer MatBuffer {
    Material materials[];
};
layout(std430, binding = 1) buffer LightBuffer{
    Quad lights[];
};

// Extract important information from the voxel world space given the map position 
bool extractVoxel(ivec3 mapPos, out Material material){
    material = Material(vec3(0.5), 2, 0, 0, vec2(0));
    if (imageLoad(world, mapPos).x == 1){
        return true; 
    }
    return false; 
}

// Get the direction vector for cube texture map sampling 
vec3 cubeDirection(vec3 hitPoint, ivec3 mapPos){
    vec3 centerCube = vec3(mapPos) + vec3(0.5);
    return hitPoint - centerCube;
}

// Determine whether the ray is front facing with the voxel 
void voxelFrontFace(inout HitRecord record, Ray ray, ivec3 mapPos){
    vec3 centerCube = vec3(mapPos) + vec3(0.5);
    vec3 toHitPoint = record.pointHit - centerCube;

    record.frontFace = dot(ray.direction, toHitPoint) < 0;
}

// Branchless DDA with help from https://www.shadertoy.com/view/4dX3zl and https://www.shadertoy.com/view/mtyfRV (I know how branched DDA works, but this is more efficient)
bool rayMarch(Ray ray, inout HitRecord record, inout uvec4 state){
    vec3 rayDirSign = sign(ray.direction);
    ivec3 mapPos = ivec3(floor(ray.origin));   
    vec3 deltaDist = abs(vec3(length(ray.direction)) / ray.direction);
    ivec3 rayStep = ivec3(rayDirSign);
    vec3 sideDist = (rayDirSign * (vec3(mapPos) - ray.origin) + (rayDirSign * 0.5 + 0.5)) * deltaDist;
    vec3 mask; Material material;

    for (int i; i < maxRaySteps; i++){
        if (extractVoxel(mapPos, material)){
            record.normalVector = -rayDirSign * mask;
            record.tValues.t = dot(record.normalVector, vec3(mapPos) + max(vec3(0), record.normalVector) - ray.origin) / dot(record.normalVector, ray.direction);

            voxelFrontFace(record, ray, mapPos);
            record.pointHit = rayIntersectPoint(ray, record.tValues.t);    
            scatter(material.materialID, material.materialParameter, ray, record, state);  
            record.objectColor = applyTexture(material.color, material.textureID, cubeDirection(record.pointHit, mapPos));   

            return true;
        }

        mask = step(sideDist.xyz, min(sideDist.yzx, sideDist.zxy));

        sideDist += mask * deltaDist;
        mapPos += ivec3(mask) * rayStep;
    }
    return false;
}

// Create a gradient from the top of the screen to the bottom of the screen based on the ray's y direction 
vec3 gradientColor(vec3 rayDirection){
    float rayDirY = normalize(rayDirection).y;
    float t = 0.5 * (rayDirY + 1.0);

    vec3 colorTop = vec3(1.0, 1.0, 1.0);
    vec3 colorBottom = vec3(0.5, 0.7, 1.0);

    return mix(colorTop, colorBottom, t);
}

// Return the background color
vec3 backgroundColor(vec3 rayDir){
    return gradientColor(rayDir);
}

// Sample within the pixel's square from -0.5 to 0.5 in order to do some antialiasing (also stratify to increase dimensionality but converge faster for randomness)
vec2 samplePixel(int i, int j, inout uvec4 state){
    float pixelX = ((i + rand(state)) * invRootSPP) - 0.5;
    float pixelY = ((j + rand(state)) * invRootSPP) - 0.5;
    return vec2(pixelX, pixelY);
}

// Construct a ray from a camera to the viewport depending on the pixel coordinate (use stratified sampling also)
Ray constructCameraRay(ivec2 pixelCoord, int i, int j, inout uvec4 state){
    vec2 sampledVector = samplePixel(i, j, state);
    vec3 rayDir = camera.initPixelPos + (pixelCoord.x + sampledVector.x) * camera.pixelDX + (pixelCoord.y + sampledVector.y) * camera.pixelDY - camera.position;
    return Ray(camera.position, rayDir);
}


// Check if a light is visible 
bool lightVisible(vec3 objectNormal, Ray ray, float lightTime, int lightIndex){
    if (dot(objectNormal, ray.direction) <= 0){ // If the normal vector of the record that points against the origin of the ray is at all antiparallel to the lightray, the light is on the opposite side of the object
        return false;
    }

    Interval lightInterval = {rayMin, lightTime};
    
    uvec4 state = uvec4(0);
    HitRecord record = initDefaultHitRecord();
    rayMarch(ray, record, state);
    return true;
}

// Get the light's radiance through the modified version of the rendering equation
vec3 getLightRadiance(HitRecord record, Ray lightRay, int lightIndex, float lightPDF){
    return lambertianBRDF(record.objectColor) * scatteredCos(record.normalVector, lightRay.direction) * lights[lightIndex].color / lightPDF;
}

// Direct Lighting for lambertian materials with direct light sampling (don't include BRDF sampling because it doesn't matter / help for a Lambertian BRDF that's constant)
void directLighting(HitRecord record, inout vec3 accumulatedColor, vec3 throughput, inout uvec4 state){    
    Ray lightRay; float lightTime;

    vec3 directLight = vec3(0); Reservoir lightReservoir;
    
    for (int i = 0; i < badLightSamples; i++){ // Generate a bunch of bad samples and add them to the reservoir
        int lightIndex = randInt(state, 0, numLights);

        float lightPDF = quadLightPDF(lights[lightIndex], record, lightTime, lightRay, state);
        float pHat = length(getLightRadiance(record, lightRay, lightIndex, lightPDF)); // This is the weight given for weighted importance sampling (we're sampling from the PDF of the rendering equation without knowing what it is)

        float lightWeight = pHat * numLights / badLightSamples; // Get the final light weight by multiplying the sampled pHat by the number of lights (because the uniform pdf for the light sampling is 1 / numLights) and dividing by the total number of bad light samples for the w_i term. 

        updateReservoir(lightReservoir, lightIndex, lightWeight, state);
    }

    int lightIndex = lightReservoir.lightIndex;
    float weightSum = lightReservoir.sumWeight;

    float lightPDF = quadLightPDF(lights[lightIndex], record, lightTime, lightRay, state);

    if (!lightVisible(record.normalVector, lightRay, lightTime, lightIndex)){
        return; // Don't do anything if the light isn't visible.
    }

    vec3 radiance = getLightRadiance(record, lightRay, lightIndex, lightPDF);
    float pHat = length(radiance);

    accumulatedColor += weightSum / pHat * radiance * throughput; // Add the light's radiance to the accumulated color with the Monte Carlo integration of getting the W_r with weightSum / pHat and multiplying that quantity by the radiance and the throughput 
} 

// Get the pixel color while still reflecting the ray (bouncing it off of surfaces)
vec3 pixelColor(Ray ray, inout uvec4 state, out TemporalRecord tempRecord){
    vec3 accumulatedColor = vec3(0); vec3 throughput = vec3(1);
    int prevMaterialID;
    
    for (int bounce = 0; bounce < maxBounces; bounce++){
        HitRecord record = initDefaultHitRecord();

        if (!rayMarch(ray, record, state)){
            accumulatedColor += throughput * backgroundColor(ray.direction);
            
            if (bounce == 0){
                tempRecord = TemporalRecord(false, vec3(0)); // Set the temporal record to show no hits
            }
            
            break;
        } 

        if (bounce == 0){
            tempRecord = TemporalRecord(true, record.pointHit); // Set the temporal record to show the hit
        }
        
        if (record.isLight){ 
            if (bounce == 0 || prevMaterialID != LAMBERTIAN){ // Check these conditions to avoid double dipping the light source with the direct light sampling. If the previous material was lambertian, then I already accounted for the direct light. 
                accumulatedColor += throughput * record.objectColor;
            } 
            break; // Break at the light (separate from regular renderers because it allows me to simplify calculations)
        } 

        prevMaterialID = record.materialID; // Set the previous material ID for the above calculations
        if (record.materialID == LAMBERTIAN && numLights > 0){
            directLighting(record, accumulatedColor, throughput, state);
        } 
        
        throughput *= record.objectColor; // Note that this implicitly applies the rendering equation (because for lambertian materials all the terms cancel out to just multiply by the object color)
    
        if (record.didScatter){ // If it did scatter, set the new ray equal to the scattered ray
            ray = record.scatteredRay;
        } else { // If it didn't scatter, break here 
            accumulatedColor += throughput;
            break;
        }
        
        // Russian Roulette path termination with assistance from https://www.pbr-book.org/3ed-2018/Light_Transport_I_Surface_Reflection/Path_Tracing 
        if (bounce <= 3){
            continue;
        }
       
        float p = maxVector(throughput);
        if (rand(state) > p){
            break;
        } 
        throughput *= 1 / p; //Add the additional light to the throughput we get from randomly terminating paths
    }
    return accumulatedColor;
}

// Gamut correction
vec3 gamutCorrect(vec3 pixel){
    return sqrt(pixel);
}

// Implement basic antialiasing (with stratified random sampling to make the Monte Carlo path tracing converge faster at the cost of increasing dimensions) using a random point in the pixel to shoot rays through and averaging color
vec4 antialiasing(ivec2 pixelCoord, inout uvec4 state, out TemporalRecord tempRecord){
    vec3 pixel = initDefaultVec();
    for (int i = 0; i < rootSPP; i++){
        for (int j = 0; j < rootSPP; j++){
            Ray cameraRay = constructCameraRay(pixelCoord, i, j, state);
            pixel += pixelColor(cameraRay, state, tempRecord);
        }
    }
    return vec4(gamutCorrect(pixel / pow(rootSPP, 2)), 1);
}

// Main Function
void main(){
    ivec2 pixelCoord = ivec2(gl_GlobalInvocationID.xy); // Get the global invocation ID in order to determine the exact pixel location. 
    uvec4 state = imageLoad(seeds, pixelCoord);

    TemporalRecord tempRecord;
    vec4 pixel = antialiasing(pixelCoord, state, tempRecord);

    imageStore(seeds, pixelCoord, state);
    applyTAA(pixelCoord, pixel, tempRecord);
}