// Initialize the version
#version 460 core

layout(binding = 1) uniform sampler2D brickWall;
layout(binding = 2) uniform sampler2D earth;

// Import files here using the "include" statement that Python processes with string processing and txt file processing
#include "Random"
#include "Vectors"
#include "Ray"
#include "Interval"
#include "HitRecord"
#include "Materials"
#include "Camera"
#include "Textures"
#include "Sphere"
#include "Quad"

// Set up invocation size and take in the screen texture to modify it per pixel. Note that the size volume is 32 (which is optimized for NVIDIA gpus rather than AMD gpus [which prefer a size of multiples of 64])
layout(local_size_x = 8, local_size_y = 4, local_size_z = 1) in;
layout(rgba32f, binding = 0) uniform image2D screen;
layout(rgba32ui, binding = 1) uniform uimage2D seeds;

layout(std430, binding = 0) buffer scene1 {
    sphere3 spheres[];
};
layout(std430, binding = 1) buffer scene2 {
    quad3 quads[];
};

uniform int numSpheres;
uniform int numQuads;
uniform int maxBounces;
uniform int rootSPP;
uniform float invRootSPP;
uniform viewerCamera camera;

// Create a gradient from the top of the screen to the bottom of the screen based on the ray's y direction 
vec3 gradientColor(vec3 rayDirection){
    float rayDirY = normalize(rayDirection).y;
    float t = 0.5 * (rayDirY + 1.0);

    vec3 colorTop = vec3(1.0, 1.0, 1.0);
    vec3 colorBottom = vec3(0.5, 0.7, 1.0);

    return mix(colorTop, colorBottom, t);
}

// Sample within the pixel's square from -0.5 to 0.5 in order to do some antialiasing (also stratify to increase dimensionality but converge faster for randomness)
vec2 samplePixel(int i, int j, inout uvec4 state){
    float pixelX = ((i + rand(state)) * invRootSPP) - 0.5;
    float pixelY = ((j + rand(state)) * invRootSPP) - 0.5;
    return vec2(pixelX, pixelY);
}

// Construct a ray from a camera to the viewport depending on the pixel coordinate (use stratified sampling also)
ray3 constructCameraRay(ivec2 pixelCoord, int i, int j, inout uvec4 state){
    vec2 sampledVector = samplePixel(i, j, state);
    vec3 rayDir = camera.initPixelPos + (pixelCoord.x + sampledVector.x) * camera.pixelDX + (pixelCoord.y + sampledVector.y) * camera.pixelDY - camera.position;
    struct ray3 ray = {camera.position, rayDir};
    return ray;
}

// Check if a ray hits any hittable and update a hit record to show the ray's color and reflect that change. 
bool hit(ray3 ray, inout hitRecord record, inout uvec4 state){
    bool didHit = false; 
    for (int i = 0; i < numSpheres; i++){
        if (hitSphere(spheres[i], ray, record, state)){
            didHit = true; 
        }
    }
    for (int i = 0; i < numQuads; i++){
        if (hitQuad(quads[i], ray, record, state)){
            didHit = true;
        }
    }
    return didHit;
}

// Get the pixel color while still reflecting the ray (bouncing it off of surfaces)
vec3 pixelColor(ray3 ray, inout uvec4 state){
    vec3 throughput = vec3(1.0, 1.0, 1.0);
    
    for (int i = 0; i < maxBounces; i++){
        hitRecord record = initDefaultHitRecord();

        if (!hit(ray, record, state)){
            return throughput * gradientColor(ray.direction);
        } 

        if (record.isLight){
            return record.rayColor * throughput;
        }
    
        if (record.didScatter){
            throughput *= record.rayColor;
            ray = record.scatteredRay;
        } else {
            break;
        }
    }
    return vec3(0.0, 0.0, 0.0);
}

// Gamut correction
vec3 gamutCorrect(vec3 pixel){
    return sqrt(pixel);
}

// Implement basic antialiasing using a random point in the pixel to shoot rays through and averaging color
vec4 antialiasing(ivec2 pixelCoord, inout uvec4 state){
    vec3 pixel = initDefaultVec();
    for (int i = 0; i < rootSPP; i++){
        for (int j = 0; j < rootSPP; j++){
            ray3 cameraRay = constructCameraRay(pixelCoord, i, j, state);
            pixel += pixelColor(cameraRay, state);
        }
    }
    return vec4(gamutCorrect(pixel / pow(rootSPP, 2)), 1);
}

// Main Function
void main(){
    ivec2 pixelCoord = ivec2(gl_GlobalInvocationID.xy); // Get the global invocation ID in order to determine the exact pixel location. 
    uvec4 state = imageLoad(seeds, pixelCoord);
    vec4 pixel = antialiasing(pixelCoord, state);

    imageStore(seeds, pixelCoord, state);
    imageStore(screen, pixelCoord, pixel);
}